{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63278e502b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/OneDrive/dev/backend/python/dl/nlp-mac/preprocessing/torchtext/data_loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     '''\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = DataLoader(\n",
    "    train_fn='./review.sorted.uniq.refined.tok.shuf.train.tsv',\n",
    "    batch_size=256,\n",
    "    valid_ratio=.2,\n",
    "    device=-1,\n",
    "    max_vocab=999999,\n",
    "    min_freq=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|train|=195021\n",
      "|valid|=48755\n"
     ]
    }
   ],
   "source": [
    "print(\"|train|=%d\" % len(loaders.train_loader.dataset))\n",
    "print(\"|valid|=%d\" % len(loaders.valid_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|vocab|=17061\n",
      "|label|=2\n"
     ]
    }
   ],
   "source": [
    "print(\"|vocab|=%d\" % len(loaders.text.vocab))\n",
    "print(\"|label|=%d\" % len(loaders.label.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mini-batch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 11])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(loaders.train_loader))\n",
    "\n",
    "print(data.text.shape)\n",
    "print(data.label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNK',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_default_unk_index',\n",
       " 'extend',\n",
       " 'freqs',\n",
       " 'itos',\n",
       " 'load_vectors',\n",
       " 'set_vectors',\n",
       " 'stoi',\n",
       " 'unk_index',\n",
       " 'vectors']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(loaders.text.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders.text.vocab.stoi['배송']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'잘'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders.text.vocab.itos[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0: <unk>\t0\n",
      "    1: <pad>\t0\n",
      "    2: .\t240674\n",
      "    3: 고\t138275\n",
      "    4: 이\t132581\n",
      "    5: 하\t113998\n",
      "    6: 도\t93852\n",
      "    7: 네요\t91795\n",
      "    8: 좋\t89116\n",
      "    9: 에\t85388\n",
      "   10: 는\t79666\n",
      "   11: 가\t64782\n",
      "   12: 은\t60988\n",
      "   13: 는데\t52505\n",
      "   14: 아요\t49804\n",
      "   15: 게\t49733\n",
      "   16: 잘\t48820\n",
      "   17: 어요\t46072\n",
      "   18: 배송\t43699\n",
      "   19: 있\t41614\n",
      "   20: 습니다\t39560\n",
      "   21: 했\t39058\n",
      "   22: 안\t35755\n",
      "   23: 을\t34958\n",
      "   24: 한\t33042\n",
      "   25: ~\t30086\n",
      "   26: 구매\t29246\n",
      "   27: 같\t27737\n",
      "   28: 너무\t27433\n",
      "   29: 합니다\t27040\n",
      "   30: 거\t26911\n",
      "   31: 지\t26375\n",
      "   32: ..\t24957\n",
      "   33: !\t24509\n",
      "   34: 어\t24087\n",
      "   35: 다\t23402\n",
      "   36: ,\t23023\n",
      "   37: 가격\t22861\n",
      "   38: 되\t22396\n",
      "   39: ?\t21954\n",
      "   40: 것\t21296\n",
      "   41: 았\t21026\n",
      "   42: 제품\t20964\n",
      "   43: 들\t20757\n",
      "   44: 으로\t20609\n",
      "   45: 쓰\t20311\n",
      "   46: 아\t20180\n",
      "   47: 만\t20049\n",
      "   48: 받\t20028\n",
      "   49: 로\t19614\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    word = loaders.text.vocab.itos[i]\n",
    "    print('%5d: %s\\t%d' % (i, word, loaders.text.vocab.freqs[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore text from tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 266,    6,  334,    3,  126,    6,   16,   38,   63,  355, 1783])\n"
     ]
    }
   ],
   "source": [
    "print(data.text[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "색 도 예쁘 고 포장 도 잘 되 서 빨리 왔어요\n"
     ]
    }
   ],
   "source": [
    "x = data.text[-1]\n",
    "line = []\n",
    "for x_i in x:\n",
    "    line += [loaders.text.vocab.itos[x_i]]\n",
    "    \n",
    "print(' '.join(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
